{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf77d37f",
   "metadata": {},
   "source": [
    "Corroborar si este es mas rapido al no seleccionar días separados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133172ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>t2m</th>\n",
       "      <th>d2m</th>\n",
       "      <th>tp</th>\n",
       "      <th>t2m_min</th>\n",
       "      <th>t2m_max</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>ws10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-63.00</td>\n",
       "      <td>296.222351</td>\n",
       "      <td>291.317322</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>292.111572</td>\n",
       "      <td>301.740601</td>\n",
       "      <td>None</td>\n",
       "      <td>2.047017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-62.75</td>\n",
       "      <td>296.385437</td>\n",
       "      <td>290.895935</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>292.195557</td>\n",
       "      <td>302.031616</td>\n",
       "      <td>None</td>\n",
       "      <td>1.994279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-62.50</td>\n",
       "      <td>296.388855</td>\n",
       "      <td>290.684509</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>292.150635</td>\n",
       "      <td>301.816772</td>\n",
       "      <td>None</td>\n",
       "      <td>1.910873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-62.25</td>\n",
       "      <td>296.367371</td>\n",
       "      <td>290.656189</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>292.385010</td>\n",
       "      <td>301.488647</td>\n",
       "      <td>None</td>\n",
       "      <td>1.794032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-62.00</td>\n",
       "      <td>296.280457</td>\n",
       "      <td>290.852478</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>292.685791</td>\n",
       "      <td>301.119507</td>\n",
       "      <td>None</td>\n",
       "      <td>1.605475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42305</th>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-62.00</td>\n",
       "      <td>288.465057</td>\n",
       "      <td>280.686890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>282.887146</td>\n",
       "      <td>297.533447</td>\n",
       "      <td>None</td>\n",
       "      <td>2.818601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42306</th>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-61.75</td>\n",
       "      <td>288.343475</td>\n",
       "      <td>280.871460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>282.758240</td>\n",
       "      <td>297.195557</td>\n",
       "      <td>None</td>\n",
       "      <td>2.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42307</th>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-61.50</td>\n",
       "      <td>288.132050</td>\n",
       "      <td>281.157104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>282.285583</td>\n",
       "      <td>297.222900</td>\n",
       "      <td>None</td>\n",
       "      <td>2.645121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42308</th>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-61.25</td>\n",
       "      <td>288.270721</td>\n",
       "      <td>281.509644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>282.680115</td>\n",
       "      <td>297.211182</td>\n",
       "      <td>None</td>\n",
       "      <td>2.532038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42309</th>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-61.00</td>\n",
       "      <td>288.626678</td>\n",
       "      <td>282.159546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>283.687927</td>\n",
       "      <td>297.152588</td>\n",
       "      <td>None</td>\n",
       "      <td>2.464709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42310 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  latitude  longitude         t2m         d2m        tp  \\\n",
       "0      2023-01-01     -33.0     -63.00  296.222351  291.317322  0.000448   \n",
       "1      2023-01-01     -33.0     -62.75  296.385437  290.895935  0.000464   \n",
       "2      2023-01-01     -33.0     -62.50  296.388855  290.684509  0.000487   \n",
       "3      2023-01-01     -33.0     -62.25  296.367371  290.656189  0.000407   \n",
       "4      2023-01-01     -33.0     -62.00  296.280457  290.852478  0.000307   \n",
       "...           ...       ...        ...         ...         ...       ...   \n",
       "42305  2025-08-28     -32.0     -62.00  288.465057  280.686890  0.000000   \n",
       "42306  2025-08-28     -32.0     -61.75  288.343475  280.871460  0.000000   \n",
       "42307  2025-08-28     -32.0     -61.50  288.132050  281.157104  0.000000   \n",
       "42308  2025-08-28     -32.0     -61.25  288.270721  281.509644  0.000000   \n",
       "42309  2025-08-28     -32.0     -61.00  288.626678  282.159546  0.000000   \n",
       "\n",
       "          t2m_min     t2m_max wind_speed      ws10  \n",
       "0      292.111572  301.740601       None  2.047017  \n",
       "1      292.195557  302.031616       None  1.994279  \n",
       "2      292.150635  301.816772       None  1.910873  \n",
       "3      292.385010  301.488647       None  1.794032  \n",
       "4      292.685791  301.119507       None  1.605475  \n",
       "...           ...         ...        ...       ...  \n",
       "42305  282.887146  297.533447       None  2.818601  \n",
       "42306  282.758240  297.195557       None  2.797000  \n",
       "42307  282.285583  297.222900       None  2.645121  \n",
       "42308  282.680115  297.211182       None  2.532038  \n",
       "42309  283.687927  297.152588       None  2.464709  \n",
       "\n",
       "[42310 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "# import sqlite3\n",
    "# BASE_DIR = Path().resolve()  \n",
    "\n",
    "# DB_PATH = BASE_DIR.parent / \"backend\" / \"data\" / \"mi_base_de_datos5.db\"\n",
    "\n",
    "# conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# # 2) Lée los últimos 20 registros (ordenados por fecha decreciente)\n",
    "# df_clima = pd.read_sql_query(\"\"\"\n",
    "#     SELECT *\n",
    "#       FROM climate_test\n",
    "#      ORDER BY date\n",
    "# \"\"\", conn)\n",
    "\n",
    "# conn.close()\n",
    "# df_clima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67532cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB_PATH = BASE_DIR.parent / \"backend\" / \"data\" / \"mi_base_de_datos5.db\"\n",
    "\n",
    "# conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# cur = conn.cursor()\n",
    "# cur.executescript(\"\"\"\n",
    "# CREATE INDEX IF NOT EXISTS idx_ct_dll  ON climate_test(date, latitude, longitude);\n",
    "# CREATE INDEX IF NOT EXISTS idx_wxt_dll ON climate_wxt2(date, latitude, longitude);\n",
    "# \"\"\")\n",
    "\n",
    "# # update: reemplaza solo con valores no nulos de climate_wxt\n",
    "# cur.executescript(\"\"\"\n",
    "# UPDATE climate_test AS t\n",
    "# SET\n",
    "#   t2m_min = COALESCE((\n",
    "#       SELECT w.t2m_min\n",
    "#       FROM climate_wxt2 w\n",
    "#       WHERE w.date = t.date\n",
    "#         AND w.latitude  = t.latitude\n",
    "#         AND w.longitude = t.longitude\n",
    "#   ), t.t2m_min),\n",
    "#   t2m_max = COALESCE((\n",
    "#       SELECT w.t2m_max\n",
    "#       FROM climate_wxt2 w\n",
    "#       WHERE w.date = t.date\n",
    "#         AND w.latitude  = t.latitude\n",
    "#         AND w.longitude = t.longitude\n",
    "#   ), t.t2m_max),\n",
    "#   ws10 = COALESCE((\n",
    "#       SELECT w.ws10\n",
    "#       FROM climate_wxt2 w\n",
    "#       WHERE w.date = t.date\n",
    "#         AND w.latitude  = t.latitude\n",
    "#         AND w.longitude = t.longitude\n",
    "#   ), t.ws10)\n",
    "# WHERE EXISTS (\n",
    "#   SELECT 1 FROM climate_wxt2 w\n",
    "#   WHERE w.date = t.date\n",
    "#     AND w.latitude  = t.latitude\n",
    "#     AND w.longitude = t.longitude\n",
    "# );\n",
    "# \"\"\")\n",
    "# conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1384609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cdsapi\n",
    "\n",
    "\n",
    "\n",
    "# TMP_DIR   = \"Clima\\\\tmp_test20d\"\n",
    "# CDS_URL   = 'https://cds.climate.copernicus.eu/api'\n",
    "# CDS_KEY   = 'd9af180c-f7f8-4a2e-8029-09018fb8c920'\n",
    "# c = cdsapi.Client(url=CDS_URL, key=CDS_KEY)\n",
    "# # bbox = [N, W, S, E] en grados; ajusta a tu zona\n",
    "# BBOX = [-31.9, -63.5, -32.6, -63.0]  # aprox VM y alrededores\n",
    "\n",
    "# c.retrieve(\n",
    "#     'reanalysis-era5-land',\n",
    "#     {\n",
    "#         'variable': [\n",
    "#             '2m_temperature','2m_dewpoint_temperature',\n",
    "#             'total_precipitation','10m_u_component_of_wind','10m_v_component_of_wind'\n",
    "#         ],\n",
    "#         'year': ['2025'],     # o un rango\n",
    "#         'month': ['01'],\n",
    "#         'day': [f'{d:02d}' for d in range(1,32)],\n",
    "#         'time': [f'{h:02d}:00' for h in range(24)],  # horario\n",
    "#         'area': BBOX,    # N, W, S, E\n",
    "#         'format': 'netcdf',\n",
    "#     },\n",
    "#     'era5land_vm_2024_2025.nc'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e987b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cdsapi, calendar, time\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import os, cdsapi, calendar, time, datetime as dt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "CDS_URL   = 'https://cds.climate.copernicus.eu/api'\n",
    "CDS_KEY   = 'd9af180c-f7f8-4a2e-8029-09018fb8c920'\n",
    "c = cdsapi.Client(url=CDS_URL, key=CDS_KEY)\n",
    "\n",
    "\n",
    "# --- Área (VM +- ~0.1°) ---\n",
    "BBOX = [-32.3, -63.3, -32.5, -63.1]  # [N, W, S, E]\n",
    "\n",
    "# --- Variables en 2 grupos para bajar coste por request ---\n",
    "VAR_GROUPS = [\n",
    "    ['2m_temperature','2m_dewpoint_temperature','total_precipitation'],\n",
    " \n",
    "]\n",
    "\n",
    "OUTDIR = 'climate_data'\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# === Rango temporal ===\n",
    "START_YEAR = 2021\n",
    "today = dt.date.today()\n",
    "END_YEAR  = today.year         # p.ej. 2025\n",
    "END_MONTH = today.month        # p.ej. 9\n",
    "\n",
    "def days_in_month_limited(year: int, month: int):\n",
    "    \"\"\"Lista de días válidos del mes. Si es el mes actual, corta en 'hoy'.\"\"\"\n",
    "    ndays = calendar.monthrange(year, month)[1]\n",
    "    last_day = ndays\n",
    "    if year == today.year and month == today.month:\n",
    "        last_day = min(last_day, today.day)\n",
    "    return [f'{d:02d}' for d in range(1, last_day + 1)]\n",
    "\n",
    "def months_for_year(year: int):\n",
    "    \"\"\"Meses válidos para ese año (si es el actual: 1..mes_actual).\"\"\"\n",
    "    if year < END_YEAR:\n",
    "        return list(range(1, 13))\n",
    "    if year == END_YEAR:\n",
    "        return list(range(1, END_MONTH + 1))\n",
    "    return []  # por si acaso\n",
    "\n",
    "def retrieve_month(year, month, variables, bbox=BBOX, outdir=OUTDIR, tag='grp', retries=3):\n",
    "    yyyy, mm = f'{year:04d}', f'{month:02d}'\n",
    "    target = os.path.join(outdir, f'era5land_{yyyy}_{mm}_{tag}.nc')\n",
    "    if os.path.exists(target):\n",
    "        print(f'→ Ya existe {target}, salto.')\n",
    "        return target\n",
    "\n",
    "    days = days_in_month_limited(year, month)\n",
    "    if not days:\n",
    "        print(f'→ Sin días válidos para {yyyy}-{mm}, salto.')\n",
    "        return None\n",
    "\n",
    "    req = {\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'netcdf',\n",
    "        'variable': variables,\n",
    "        'year': [yyyy],\n",
    "        'month': [mm],\n",
    "        'day': days,\n",
    "        'time': [f'{h:02d}:00' for h in range(24)],\n",
    "        'area': bbox,        # [N, W, S, E]\n",
    "    }\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            print(f\"Descargando {yyyy}-{mm} [{tag}] (días={len(days)})…\")\n",
    "            c.retrieve('reanalysis-era5-land', req, target)\n",
    "            print(f\"✔ Guardado {target} ({os.path.getsize(target):,} bytes)\")\n",
    "            return target\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ intento {attempt+1}/{retries} falló: {e}\")\n",
    "            if attempt == retries - 1:\n",
    "                raise\n",
    "            time.sleep(15 * (attempt + 1))\n",
    "    return None\n",
    "\n",
    "# === 1) Descarga (por mes y grupo) ===\n",
    "files = []\n",
    "for y in range(START_YEAR, END_YEAR + 1):\n",
    "    for m in months_for_year(y):\n",
    "        for gi, group in enumerate(VAR_GROUPS):\n",
    "            f = retrieve_month(y, m, group, tag=f'g{gi}')\n",
    "            if f is not None:\n",
    "                files.append(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57cec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, zipfile\n",
    "import xarray as xr\n",
    "\n",
    "MAGIC = {\n",
    "    b'CDF': 'netcdf3',\n",
    "    b'\\x89HDF\\r\\n\\x1a\\n': 'netcdf4',\n",
    "    b'GRIB': 'grib',\n",
    "    b'PK\\x03\\x04': 'zip',\n",
    "    b'<!DOCTYP': 'html',\n",
    "    b'<html': 'html',\n",
    "    b'{': 'json',\n",
    "}\n",
    "\n",
    "def sniff_kind(path, nbytes=16):\n",
    "    with open(path, 'rb') as f:\n",
    "        head = f.read(nbytes)\n",
    "    for sig, kind in MAGIC.items():\n",
    "        if head.startswith(sig):\n",
    "            return kind\n",
    "    return 'unknown'\n",
    "\n",
    "def open_cds_file(path, tmpdir=None):\n",
    "    kind = sniff_kind(path)\n",
    "    print(f\"[sniff] {path} -> {kind}\")\n",
    "\n",
    "    if kind in ('netcdf3','netcdf4'):\n",
    "        return xr.open_dataset(path, engine='netcdf4')\n",
    "\n",
    "    if kind == 'grib':\n",
    "        return xr.open_dataset(path, engine='cfgrib')  # requiere cfgrib/eccodes\n",
    "\n",
    "    if kind == 'zip':\n",
    "        if tmpdir is None:\n",
    "            tmpdir = os.path.join(os.path.dirname(path), \"_unzip\")\n",
    "        os.makedirs(tmpdir, exist_ok=True)\n",
    "        with zipfile.ZipFile(path) as z:\n",
    "            z.extractall(tmpdir)\n",
    "            members = z.namelist()\n",
    "        nc_inside   = [m for m in members if m.lower().endswith('.nc')]\n",
    "        grib_inside = [m for m in members if m.lower().endswith(('.grib','.grb','.grib2'))]\n",
    "        if nc_inside:\n",
    "            return xr.open_dataset(os.path.join(tmpdir, nc_inside[0]), engine='netcdf4')\n",
    "        if grib_inside:\n",
    "            return xr.open_dataset(os.path.join(tmpdir, grib_inside[0]), engine='cfgrib')\n",
    "        raise OSError(\"ZIP no contiene .nc ni .grib\")\n",
    "\n",
    "    if kind in ('html','json','unknown'):\n",
    "        with open(path, 'rb') as f:\n",
    "            txt = f.read(400).decode('utf-8', errors='replace')\n",
    "        raise OSError(f\"El archivo no es NetCDF/GRIB. Primeros bytes:\\n{txt[:400]}\")\n",
    "    \n",
    "\n",
    "\n",
    "import os, zipfile, uuid, shutil\n",
    "import xarray as xr\n",
    "\n",
    "MAGIC = {\n",
    "    b'CDF': 'netcdf3',\n",
    "    b'\\x89HDF\\r\\n\\x1a\\n': 'netcdf4',\n",
    "    b'GRIB': 'grib',\n",
    "    b'PK\\x03\\x04': 'zip',\n",
    "    b'<!DOCTYP': 'html',\n",
    "    b'<html': 'html',\n",
    "    b'{': 'json',\n",
    "}\n",
    "\n",
    "def sniff_kind(path, nbytes=16):\n",
    "    with open(path, 'rb') as f:\n",
    "        head = f.read(nbytes)\n",
    "    for sig, kind in MAGIC.items():\n",
    "        if head.startswith(sig):\n",
    "            return kind\n",
    "    return 'unknown'\n",
    "\n",
    "def open_cds_file(path):\n",
    "    kind = sniff_kind(path)\n",
    "    print(f\"[sniff] {path} -> {kind}\")\n",
    "\n",
    "    if kind in ('netcdf3', 'netcdf4'):\n",
    "        ds = xr.open_dataset(path, engine='netcdf4')\n",
    "        return ds  # cierra con ds.close() cuando termines\n",
    "\n",
    "    if kind == 'grib':\n",
    "        ds = xr.open_dataset(path, engine='cfgrib')\n",
    "        return ds  # cierra con ds.close() cuando termines\n",
    "\n",
    "    if kind == 'zip':\n",
    "        base = os.path.splitext(os.path.basename(path))[0]\n",
    "        tmpdir = os.path.join(os.path.dirname(path), f\"_unzip_{base}_{uuid.uuid4().hex}\")\n",
    "        os.makedirs(tmpdir, exist_ok=True)\n",
    "\n",
    "        # Extraer\n",
    "        with zipfile.ZipFile(path) as z:\n",
    "            z.extractall(tmpdir)\n",
    "            members = z.namelist()\n",
    "\n",
    "        # Buscar archivo interno\n",
    "        candidates_nc   = [m for m in members if m.lower().endswith('.nc')]\n",
    "        candidates_grib = [m for m in members if m.lower().endswith(('.grib', '.grb', '.grib2'))]\n",
    "        if candidates_nc:\n",
    "            inner = os.path.join(tmpdir, candidates_nc[0]); engine = 'netcdf4'\n",
    "        elif candidates_grib:\n",
    "            inner = os.path.join(tmpdir, candidates_grib[0]); engine = 'cfgrib'\n",
    "        else:\n",
    "            shutil.rmtree(tmpdir, ignore_errors=True)\n",
    "            raise OSError(\"ZIP no contiene .nc ni .grib\")\n",
    "\n",
    "        # Abrir, cargar en memoria y soltar lock\n",
    "        ds = xr.open_dataset(inner, engine=engine)\n",
    "        ds.load()  # lee datos a memoria\n",
    "        shutil.rmtree(tmpdir, ignore_errors=True)  # elimina tmpdir: no hay lock porque ya cargamos\n",
    "        return ds\n",
    "\n",
    "    # Si vino HTML/JSON (error del servidor), mostrar primeros bytes\n",
    "    with open(path, 'rb') as f:\n",
    "        txt = f.read(400).decode('utf-8', errors='replace')\n",
    "    raise OSError(f\"El archivo no es NetCDF/GRIB. Primeros bytes:\\n{txt[:400]}\")\n",
    "\n",
    "\n",
    "def open_file(year,month):\n",
    "    yyyy, mm = f'{year:04d}', f'{month:02d}'\n",
    "    # admite que exista solo g0, solo g1, o ambos\n",
    "    candidates = []\n",
    "    \n",
    "    for g in ['g0']:\n",
    "        p = os.path.join(OUTDIR, f'era5land_{yyyy}_{mm}_{g}.nc')\n",
    "\n",
    "        if os.path.exists(p):\n",
    "            candidates.append(p)\n",
    "    dss = []\n",
    "    for path in candidates:\n",
    "        try:\n",
    "            ds = open_cds_file(path)  # usa tu función que decide el engine (netcdf4/cfgrib/zip)\n",
    "            dss.append(ds)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[skip] {path}: {e}\")\n",
    "\n",
    "\n",
    "    # print(nc_hourly)\n",
    "\n",
    "    ds = dss[0].copy()\n",
    "\n",
    "    # renombra la dimensión de tiempo\n",
    "    if 'valid_time' in ds.dims:\n",
    "        ds = ds.rename({'valid_time': 'time'})\n",
    "\n",
    "    # --- 2) derivar viento y convertir unidades ---\n",
    "    if {'u10','v10'}.issubset(ds.data_vars):\n",
    "        ds = ds.assign(ws10=np.hypot(ds['u10'], ds['v10']))  # m/s\n",
    "\n",
    "    def K_to_C(da): return da - 273.15\n",
    "    def m_to_mm(da): return da * 1000.0\n",
    "\n",
    "    if 't2m' in ds: ds['t2m'] = K_to_C(ds['t2m'])\n",
    "    if 'd2m' in ds: ds['d2m'] = K_to_C(ds['d2m'])\n",
    "\n",
    "    # --- 3) agregar a diario ---\n",
    "    # t2m, d2m, ws10: promedio diario; tp: suma diaria (mm/día)\n",
    "    agg_daily = {}\n",
    "\n",
    "\n",
    "\n",
    "    # t2m: promedio, mínima y máxima diaria (ya en °C)\n",
    "    if 't2m' in ds:\n",
    "        t2m_daily = ds['t2m'].resample(time='1D')\n",
    "        agg_daily['t2m']     = t2m_daily.mean()\n",
    "        agg_daily['t2m_min'] = t2m_daily.min()\n",
    "        agg_daily['t2m_max'] = t2m_daily.max()\n",
    "\n",
    "    for v in ['t2m','d2m','ws10']:\n",
    "        if v in ds: agg_daily[v] = ds[v].resample(time='1D').mean()\n",
    "    if 'tp' in ds:\n",
    "        tp_daily_m = ds['tp'].resample(time='1D').sum()  # aún en metros\n",
    "        agg_daily['tp'] = m_to_mm(tp_daily_m)            # ahora mm/día\n",
    "\n",
    "    ds_day = xr.Dataset(agg_daily).sortby('time')\n",
    "\n",
    "    # --- 4) a DataFrame \"tidy\" ---\n",
    "    df = ds_day.to_dataframe().reset_index()\n",
    "    df = df.sort_values(['time','latitude','longitude']).reset_index(drop=True)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n",
    "df_final=pd.DataFrame()\n",
    "for y in range(START_YEAR, END_YEAR + 1):\n",
    "    for m in months_for_year(y):\n",
    "        print(y,m)\n",
    "        ds = open_file(y,m)\n",
    "        if ds is not None:\n",
    "        #     ds1 = xr.open_dataset(ds)\n",
    "            df_final=pd.concat([df_final,ds])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6ff4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(\"number\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a314b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "shutil.rmtree(r\"downloads_era5land_0p1_test\\_unzip\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac835c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sqlite3\n",
    "# from pathlib import Path\n",
    "# import sqlite3\n",
    "BASE_DIR = Path().resolve()  \n",
    "\n",
    "DB_PATH = Path(BASE_DIR).parent / \"backend\" / \"data\" / \"mi_base_de_datos5.db\"\n",
    "\n",
    "def list_tables(db_path=DB_PATH):\n",
    "    with sqlite3.connect(db_path) as con:\n",
    "        cur = con.execute(\"\"\"\n",
    "            SELECT name\n",
    "            FROM sqlite_schema\n",
    "            WHERE type='table' AND name NOT LIKE 'sqlite_%'\n",
    "            ORDER BY name\n",
    "        \"\"\")\n",
    "        return [r[0] for r in cur.fetchall()]\n",
    "\n",
    "def ensure_table(df, name=\"climate_data\"):\n",
    "    # crea la tabla si no existe, usando el schema de df pero sin insertar filas\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        df.head(0).to_sql(name, con, if_exists=\"append\", index=False)\n",
    "\n",
    "def write_df(df, name=\"climate_data\"):\n",
    "    # inserta el dataframe (append)\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        df.to_sql(name, con, if_exists=\"append\", index=False, method=\"multi\", chunksize=1000)\n",
    "\n",
    "# uso\n",
    "ensure_table(df_final)      # 0) crea \"climate_data\" si no existe\n",
    "write_df(df_final)          # 1) mete el dataframe ahí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ac2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_tables(tables, db_path=DB_PATH):\n",
    "    if not tables:\n",
    "        return\n",
    "    with sqlite3.connect(db_path) as con:\n",
    "        con.execute(\"PRAGMA foreign_keys=ON\")\n",
    "        for t in tables:\n",
    "            if t.startswith(\"sqlite_\"):\n",
    "                continue  # nunca borres internas\n",
    "            con.execute(f'DROP TABLE IF EXISTS \"{t}\"')\n",
    "        con.commit()\n",
    "\n",
    "# ejemplo:\n",
    "to_drop = [\"climate_test\"]\n",
    "drop_tables(to_drop)\n",
    "print(list_tables())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "licitacion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
